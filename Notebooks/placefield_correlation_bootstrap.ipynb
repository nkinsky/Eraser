{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63bc1a14-1ea6-4b08-8717-dc1d3b07cf57",
   "metadata": {},
   "source": [
    "Notebook to calculate and save place field correlation mean and hierarchically bootstrapped values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "501557f4-f1ec-41a2-a7b5-0e32a908dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sstats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import project specific modules and enable automatic reloading\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "eraser_path = Path(os.getcwd()).parent\n",
    "reinstatement_path = eraser_path.parent / 'FearReinstatement'\n",
    "sys.path.append(str(eraser_path))\n",
    "sys.path.append(str(reinstatement_path))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import eraser_reference as err\n",
    "import er_plot_functions as er\n",
    "from plotting import Fig, pretty_plot, FigMirror, fix_xlabels\n",
    "import placefield_stability as pfs\n",
    "import Placefields as pf\n",
    "import discrimination as discr\n",
    "import ca_traces as trc\n",
    "import cell_tracking as ct\n",
    "import er_plot_functions as erp\n",
    "from helpers import flatten\n",
    "from stats_utils import resample, get_bootstrap_prob, get_bootstrap_prob_paired\n",
    "from subjects import save_df, load_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a857741d-7ea1-40ec-9598-c7c8eec6d4b8",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d13347-0409-4fe6-b288-62b9b6971ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_dict = {\"Before\" : [-2, -1], \"Before v After\" : [-1, 1], \"After\" : [1, 2], \"After2\": [2, 7],\n",
    "            \"Before v STM\" : [-1, 4], \"STM v After\" : [4, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ee60769-f7b3-40a2-ad01-6facad1a145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sesh_id = lambda row : f\"{row['arena1']}{row['day1']}_{row['arena2']}{row['day2']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b797b63c-22ca-41a7-8922-908c7b090456",
   "metadata": {},
   "source": [
    "## 2D Place field correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d39431-aa0d-4817-9e6b-2fc9e817a4a6",
   "metadata": {},
   "source": [
    "### Before (Day -2 to -1) correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e91cce1-e062-4db5-85a9-9264f7056606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>session_pair</th>\n",
       "      <th>mouse</th>\n",
       "      <th>arena1</th>\n",
       "      <th>day1</th>\n",
       "      <th>arena2</th>\n",
       "      <th>day2</th>\n",
       "      <th>pair_no</th>\n",
       "      <th>corrs_sm</th>\n",
       "      <th>shuf_corrs_sm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANI</td>\n",
       "      <td>Open-2_Open-1</td>\n",
       "      <td>Marble17</td>\n",
       "      <td>Open</td>\n",
       "      <td>-2</td>\n",
       "      <td>Open</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.101313</td>\n",
       "      <td>-0.098920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANI</td>\n",
       "      <td>Open-2_Open-1</td>\n",
       "      <td>Marble17</td>\n",
       "      <td>Open</td>\n",
       "      <td>-2</td>\n",
       "      <td>Open</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>0.137479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANI</td>\n",
       "      <td>Open-2_Open-1</td>\n",
       "      <td>Marble17</td>\n",
       "      <td>Open</td>\n",
       "      <td>-2</td>\n",
       "      <td>Open</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.074947</td>\n",
       "      <td>0.513872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANI</td>\n",
       "      <td>Open-2_Open-1</td>\n",
       "      <td>Marble17</td>\n",
       "      <td>Open</td>\n",
       "      <td>-2</td>\n",
       "      <td>Open</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.254538</td>\n",
       "      <td>-0.191718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANI</td>\n",
       "      <td>Open-2_Open-1</td>\n",
       "      <td>Marble17</td>\n",
       "      <td>Open</td>\n",
       "      <td>-2</td>\n",
       "      <td>Open</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032425</td>\n",
       "      <td>0.225420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>ANI</td>\n",
       "      <td>Open-2_Open-1</td>\n",
       "      <td>Marble25</td>\n",
       "      <td>Open</td>\n",
       "      <td>-2</td>\n",
       "      <td>Open</td>\n",
       "      <td>-1</td>\n",
       "      <td>549</td>\n",
       "      <td>0.050210</td>\n",
       "      <td>0.132236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>ANI</td>\n",
       "      <td>Open-2_Open-1</td>\n",
       "      <td>Marble25</td>\n",
       "      <td>Open</td>\n",
       "      <td>-2</td>\n",
       "      <td>Open</td>\n",
       "      <td>-1</td>\n",
       "      <td>550</td>\n",
       "      <td>0.489579</td>\n",
       "      <td>0.072793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>ANI</td>\n",
       "      <td>Open-2_Open-1</td>\n",
       "      <td>Marble25</td>\n",
       "      <td>Open</td>\n",
       "      <td>-2</td>\n",
       "      <td>Open</td>\n",
       "      <td>-1</td>\n",
       "      <td>551</td>\n",
       "      <td>-0.646671</td>\n",
       "      <td>0.015050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>ANI</td>\n",
       "      <td>Open-2_Open-1</td>\n",
       "      <td>Marble25</td>\n",
       "      <td>Open</td>\n",
       "      <td>-2</td>\n",
       "      <td>Open</td>\n",
       "      <td>-1</td>\n",
       "      <td>552</td>\n",
       "      <td>0.844345</td>\n",
       "      <td>-0.050282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>ANI</td>\n",
       "      <td>Open-2_Open-1</td>\n",
       "      <td>Marble25</td>\n",
       "      <td>Open</td>\n",
       "      <td>-2</td>\n",
       "      <td>Open</td>\n",
       "      <td>-1</td>\n",
       "      <td>553</td>\n",
       "      <td>0.382982</td>\n",
       "      <td>0.073401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1934 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Group   session_pair     mouse arena1  day1 arena2  day2  pair_no  \\\n",
       "0     ANI  Open-2_Open-1  Marble17   Open    -2   Open    -1        0   \n",
       "1     ANI  Open-2_Open-1  Marble17   Open    -2   Open    -1        1   \n",
       "2     ANI  Open-2_Open-1  Marble17   Open    -2   Open    -1        2   \n",
       "3     ANI  Open-2_Open-1  Marble17   Open    -2   Open    -1        3   \n",
       "4     ANI  Open-2_Open-1  Marble17   Open    -2   Open    -1        4   \n",
       "..    ...            ...       ...    ...   ...    ...   ...      ...   \n",
       "549   ANI  Open-2_Open-1  Marble25   Open    -2   Open    -1      549   \n",
       "550   ANI  Open-2_Open-1  Marble25   Open    -2   Open    -1      550   \n",
       "551   ANI  Open-2_Open-1  Marble25   Open    -2   Open    -1      551   \n",
       "552   ANI  Open-2_Open-1  Marble25   Open    -2   Open    -1      552   \n",
       "553   ANI  Open-2_Open-1  Marble25   Open    -2   Open    -1      553   \n",
       "\n",
       "     corrs_sm  shuf_corrs_sm  \n",
       "0    0.101313      -0.098920  \n",
       "1    0.021653       0.137479  \n",
       "2    0.074947       0.513872  \n",
       "3    0.254538      -0.191718  \n",
       "4    0.032425       0.225420  \n",
       "..        ...            ...  \n",
       "549  0.050210       0.132236  \n",
       "550  0.489579       0.072793  \n",
       "551 -0.646671       0.015050  \n",
       "552  0.844345      -0.050282  \n",
       "553  0.382982       0.073401  \n",
       "\n",
       "[1934 rows x 10 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import copy\n",
    "corr_df2 = copy(corr_df)\n",
    "corr_df2.insert(9, column=\"shuf_corrs_sm\", value=pd.concat(shuf_df_list).corrs_sm.values)\n",
    "corr_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f85e814-fb9f-419d-9b39-5301adcd3944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>session_pair</th>\n",
       "      <th>mouse</th>\n",
       "      <th>arena1</th>\n",
       "      <th>day1</th>\n",
       "      <th>arena2</th>\n",
       "      <th>day2</th>\n",
       "      <th>pair_no</th>\n",
       "      <th>corrs_sm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Learners</td>\n",
       "      <td>Shock-2_Shock-1</td>\n",
       "      <td>Marble07</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-2</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.650432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Learners</td>\n",
       "      <td>Shock-2_Shock-1</td>\n",
       "      <td>Marble07</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-2</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.612747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Learners</td>\n",
       "      <td>Shock-2_Shock-1</td>\n",
       "      <td>Marble07</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-2</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.398014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Learners</td>\n",
       "      <td>Shock-2_Shock-1</td>\n",
       "      <td>Marble07</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-2</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.183515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Learners</td>\n",
       "      <td>Shock-2_Shock-1</td>\n",
       "      <td>Marble07</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-2</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.914217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Learners</td>\n",
       "      <td>Shock-2_Shock-1</td>\n",
       "      <td>Marble27</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-2</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-1</td>\n",
       "      <td>218</td>\n",
       "      <td>0.303080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Learners</td>\n",
       "      <td>Shock-2_Shock-1</td>\n",
       "      <td>Marble27</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-2</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-1</td>\n",
       "      <td>219</td>\n",
       "      <td>0.112047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Learners</td>\n",
       "      <td>Shock-2_Shock-1</td>\n",
       "      <td>Marble27</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-2</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-1</td>\n",
       "      <td>220</td>\n",
       "      <td>0.496938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Learners</td>\n",
       "      <td>Shock-2_Shock-1</td>\n",
       "      <td>Marble27</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-2</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-1</td>\n",
       "      <td>221</td>\n",
       "      <td>0.173585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Learners</td>\n",
       "      <td>Shock-2_Shock-1</td>\n",
       "      <td>Marble27</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-2</td>\n",
       "      <td>Shock</td>\n",
       "      <td>-1</td>\n",
       "      <td>222</td>\n",
       "      <td>-0.132263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>852 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Group     session_pair     mouse arena1  day1 arena2  day2  pair_no  \\\n",
       "0    Learners  Shock-2_Shock-1  Marble07  Shock    -2  Shock    -1        0   \n",
       "1    Learners  Shock-2_Shock-1  Marble07  Shock    -2  Shock    -1        1   \n",
       "2    Learners  Shock-2_Shock-1  Marble07  Shock    -2  Shock    -1        2   \n",
       "3    Learners  Shock-2_Shock-1  Marble07  Shock    -2  Shock    -1        3   \n",
       "4    Learners  Shock-2_Shock-1  Marble07  Shock    -2  Shock    -1        4   \n",
       "..        ...              ...       ...    ...   ...    ...   ...      ...   \n",
       "218  Learners  Shock-2_Shock-1  Marble27  Shock    -2  Shock    -1      218   \n",
       "219  Learners  Shock-2_Shock-1  Marble27  Shock    -2  Shock    -1      219   \n",
       "220  Learners  Shock-2_Shock-1  Marble27  Shock    -2  Shock    -1      220   \n",
       "221  Learners  Shock-2_Shock-1  Marble27  Shock    -2  Shock    -1      221   \n",
       "222  Learners  Shock-2_Shock-1  Marble27  Shock    -2  Shock    -1      222   \n",
       "\n",
       "     corrs_sm  \n",
       "0    0.650432  \n",
       "1    0.612747  \n",
       "2   -0.398014  \n",
       "3   -0.183515  \n",
       "4    0.914217  \n",
       "..        ...  \n",
       "218  0.303080  \n",
       "219  0.112047  \n",
       "220  0.496938  \n",
       "221  0.173585  \n",
       "222 -0.132263  \n",
       "\n",
       "[852 rows x 9 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "184d9bbf-59cc-4cc2-ae37-03444e1a485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "savename_dict = {\"Before\": \"before\", \"Before v After\": \"before_after\", \"After\": \"after\", \n",
    "                 \"After2\": \"after2\", \"Before v STM\": \"before_stm\", \"STM v After\": \"stm_after\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "529a4cb3-e80c-4d4a-b2b1-d46f6e801647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_pf_corrs_before.csv saved\n",
      "group_pf_corrs_before_bootstrap.csv saved\n"
     ]
    }
   ],
   "source": [
    "save_str = savename_dict[epoch]\n",
    "save_df(corr_df_all, f\"group_pf_corrs_{save_str}\")\n",
    "save_df(df_bs, f\"group_pf_corrs_{save_str}_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4c5a8ee4-93a4-4d5f-b86e-ea75f7be552a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble07 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble07 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble12 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble12 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble24 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble24 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble27 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble27 Shock day -2 to Shock day -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:27<00:00, 358.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble06 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble06 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble11 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble11 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble29 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble29 Shock day -2 to Shock day -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:23<00:00, 422.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble17 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble17 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble18 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble18 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble19 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble19 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble20 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble20 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble25 Shock day -2 to Shock day -1\n",
      "Loading previous 2d placefield analysis for Marble25 Shock day -2 to Shock day -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:38<00:00, 259.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble07 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble07 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble12 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble12 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble24 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble24 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble27 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble27 Open day -2 to Open day -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:31<00:00, 318.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble06 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble06 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble11 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble11 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble29 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble29 Open day -2 to Open day -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:28<00:00, 352.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble17 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble17 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble18 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble18 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble19 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble19 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble20 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble20 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble25 Open day -2 to Open day -1\n",
      "Loading previous 2d placefield analysis for Marble25 Open day -2 to Open day -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:40<00:00, 248.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_pf_corrs_before.csv saved\n",
      "group_pf_corrs_before_bootstrap.csv saved\n",
      "Loading previous 2d placefield analysis for Marble07 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble07 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble12 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble12 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble24 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble24 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble27 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble27 Shock day -1 to Shock day 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:27<00:00, 368.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble06 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble06 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble11 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble11 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble29 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble29 Shock day -1 to Shock day 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:43<00:00, 227.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble17 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble17 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble18 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble18 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble19 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble19 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble20 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble20 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble25 Shock day -1 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble25 Shock day -1 to Shock day 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:35<00:00, 284.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble07 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble07 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble12 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble12 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble24 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble24 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble27 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble27 Open day -1 to Open day 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:31<00:00, 316.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble06 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble06 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble11 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble11 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble29 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble29 Open day -1 to Open day 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:47<00:00, 209.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble17 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble17 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble18 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble18 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble19 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble19 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble20 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble20 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble25 Open day -1 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble25 Open day -1 to Open day 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:59<00:00, 168.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_pf_corrs_before_after.csv saved\n",
      "group_pf_corrs_before_after_bootstrap.csv saved\n",
      "Loading previous 2d placefield analysis for Marble07 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble07 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble12 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble12 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble24 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble24 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble27 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble27 Shock day 1 to Shock day 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:25<00:00, 399.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble06 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble06 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble11 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble11 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble29 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble29 Shock day 1 to Shock day 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:22<00:00, 436.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble17 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble17 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble18 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble18 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble19 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble19 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble20 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble20 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble25 Shock day 1 to Shock day 2\n",
      "Loading previous 2d placefield analysis for Marble25 Shock day 1 to Shock day 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:31<00:00, 316.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble07 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble07 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble12 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble12 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble24 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble24 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble27 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble27 Open day 1 to Open day 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:26<00:00, 374.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble06 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble06 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble11 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble11 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble29 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble29 Open day 1 to Open day 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:22<00:00, 437.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble17 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble17 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble18 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble18 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble19 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble19 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble20 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble20 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble25 Open day 1 to Open day 2\n",
      "Loading previous 2d placefield analysis for Marble25 Open day 1 to Open day 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:32<00:00, 304.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_pf_corrs_after.csv saved\n",
      "group_pf_corrs_after_bootstrap.csv saved\n",
      "Loading previous 2d placefield analysis for Marble07 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble07 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble12 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble12 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble24 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble24 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble27 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble27 Shock day 2 to Shock day 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:24<00:00, 409.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble06 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble06 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble11 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble11 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble29 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble29 Shock day 2 to Shock day 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:15<00:00, 663.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble17 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble17 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble18 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble18 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble19 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble19 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble20 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble20 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble25 Shock day 2 to Shock day 7\n",
      "Loading previous 2d placefield analysis for Marble25 Shock day 2 to Shock day 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:30<00:00, 326.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble07 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble07 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble12 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble12 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble24 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble24 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble27 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble27 Open day 2 to Open day 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:26<00:00, 372.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble06 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble06 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble11 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble11 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble29 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble29 Open day 2 to Open day 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:16<00:00, 619.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble17 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble17 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble18 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble18 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble19 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble19 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble20 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble20 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble25 Open day 2 to Open day 7\n",
      "Loading previous 2d placefield analysis for Marble25 Open day 2 to Open day 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:31<00:00, 319.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_pf_corrs_after2.csv saved\n",
      "group_pf_corrs_after2_bootstrap.csv saved\n",
      "Loading previous 2d placefield analysis for Marble07 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble07 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble12 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble12 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble24 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble24 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble27 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble27 Shock day -1 to Shock day 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:25<00:00, 397.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble06 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble06 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble11 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble11 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble29 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble29 Shock day -1 to Shock day 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:22<00:00, 445.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble17 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble17 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble18 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble18 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble19 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble19 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble20 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble20 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble25 Shock day -1 to Shock day 4\n",
      "Loading previous 2d placefield analysis for Marble25 Shock day -1 to Shock day 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:30<00:00, 327.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble07 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble07 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble12 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble12 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble24 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble24 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble27 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble27 Open day -1 to Open day 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:27<00:00, 369.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble06 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble06 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble11 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble11 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble29 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble29 Open day -1 to Open day 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:24<00:00, 414.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble17 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble17 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble18 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble18 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble19 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble19 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble20 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble20 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble25 Open day -1 to Open day 4\n",
      "Loading previous 2d placefield analysis for Marble25 Open day -1 to Open day 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:33<00:00, 301.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_pf_corrs_before_stm.csv saved\n",
      "group_pf_corrs_before_stm_bootstrap.csv saved\n",
      "Loading previous 2d placefield analysis for Marble07 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble07 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble12 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble12 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble24 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble24 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble27 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble27 Shock day 4 to Shock day 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:25<00:00, 395.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble06 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble06 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble11 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble11 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble29 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble29 Shock day 4 to Shock day 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:21<00:00, 462.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble17 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble17 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble18 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble18 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble19 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble19 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble20 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble20 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble25 Shock day 4 to Shock day 1\n",
      "Loading previous 2d placefield analysis for Marble25 Shock day 4 to Shock day 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:30<00:00, 327.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble07 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble07 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble12 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble12 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble24 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble24 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble27 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble27 Open day 4 to Open day 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:26<00:00, 372.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble06 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble06 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble11 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble11 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble29 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble29 Open day 4 to Open day 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:23<00:00, 427.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous 2d placefield analysis for Marble17 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble17 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble18 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble18 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble19 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble19 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble20 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble20 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble25 Open day 4 to Open day 1\n",
      "Loading previous 2d placefield analysis for Marble25 Open day 4 to Open day 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:31<00:00, 312.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_pf_corrs_stm_after.csv saved\n",
      "group_pf_corrs_stm_after_bootstrap.csv saved\n"
     ]
    }
   ],
   "source": [
    "n_iter = 10000\n",
    "for epoch in [\"Before\", \"Before v After\", \"After\", \"After2\", \"Before v STM\", \"STM v After\"]:\n",
    "    df_bs, corr_df_all, shuf_df_all = [], [], []\n",
    "    resample_levels = [\"mouse\", \"session\", \"corrs_sm\"]\n",
    "    for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "        \n",
    "        for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                    [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "            df_list, df_shuf_list = [], []\n",
    "            for mouse in mice:\n",
    "                day1, day2 = day_dict[epoch]\n",
    "                df_list.append(pfs.pf_corrs_to_df(mouse, arena, day1, arena, day2))\n",
    "                df_shuf_list.append(pfs.pf_corrs_to_df(mouse, arena, day1, arena, day2, shuf_map=True))\n",
    "    \n",
    "            shuf_df = pd.concat(df_shuf_list)\n",
    "            corr_df = pd.concat(df_list)\n",
    "            corr_df.insert(0, column='Group', value=group_name)\n",
    "            corr_df.insert(1, column=\"session_pair\", value=corr_df.apply(gen_sesh_id, axis=1))\n",
    "            corr_df.insert(9, column=\"shuf_corrs_sm\", value=shuf_df.corrs_sm.values)\n",
    "            corr_df_all.append(corr_df)\n",
    "    \n",
    "            # shuf_df.insert(0, column='Group', value=group_name)\n",
    "            # shuf_df.insert(1, column=\"session_pair\", value=corr_df.apply(gen_sesh_id, axis=1))\n",
    "            # shuf_df_all.append(shuf_df)\n",
    "            \n",
    "            means, shuf_means = [], []\n",
    "            for ii in tqdm(range(n_iter)):\n",
    "                t = resample(corr_df, level=['mouse', 'session_pair', 'corrs_sm'])\n",
    "                means.append(t.corrs_sm.mean())\n",
    "                shuf_means.append(t.shuf_corrs_sm.mean())\n",
    "            df_bs.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \"Mean PF Corr\": means, \n",
    "                                      \"Shuf Mean PF Corr\": shuf_means}))\n",
    "    df_bs = pd.concat(df_bs)\n",
    "    corr_df_all = pd.concat(corr_df_all)\n",
    "    corr_df_all = corr_df_all.rename(columns={\"arena1\" : \"Arena\"})\n",
    "    corr_df_all.loc[corr_df_all.Arena == \"Open\", \"Arena\"] = \"Neutral\"\n",
    "    \n",
    "    save_str = savename_dict[epoch]\n",
    "    save_df(corr_df_all, f\"group_pf_corrs_{save_str}\")\n",
    "    save_df(df_bs, f\"group_pf_corrs_{save_str}_bootstrap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4080b37c-2dae-490c-a4f8-988da40d8fb8",
   "metadata": {},
   "source": [
    "### Calculate Before v After (Day -1 to Day 1) correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ff59c-81c0-4706-85ad-afec7239221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'Before v After'\n",
    "resample_levels = [\"mouse\", \"session\", \"corrs_sm\"]\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        df_list = []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            df_list.append(pfs.pf_corrs_to_df(mouse, arena, day1, arena, day2))\n",
    "        \n",
    "        corr_df = pd.concat(df_list)\n",
    "        corr_df.insert(0, column='Group', value=group_name)\n",
    "        corr_df.insert(1, column=\"session_pair\", value=corr_df.apply(gen_sesh_id, axis=1))\n",
    "        corr_df_all.append(corr_df)\n",
    "        means = []\n",
    "        for ii in range(10000):\n",
    "            t = resample(corr_df, level=['mouse', 'session_pair', 'corrs_sm'])\n",
    "            means.append(t.corrs_sm.mean())\n",
    "        df_bs.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \"Mean PF Corr\": means}))\n",
    "df_bs = pd.concat(df_bs)\n",
    "corr_df_all = pd.concat(corr_df_all)\n",
    "corr_df_all = corr_df_all.rename(columns={\"arena1\" : \"Arena\"})\n",
    "corr_df_all.loc[corr_df_all.Arena == \"Open\", \"Arena\"] = \"Neutral\"\n",
    "\n",
    "save_df(corr_df_all, \"group_pf_corrs_before_after\")\n",
    "save_df(df_bs, \"group_pf_corrs_before_after_bootstrap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd485a62-8f13-4660-a0b7-09a09646bdfe",
   "metadata": {},
   "source": [
    "### After correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf7c9c-2742-4f5d-82ae-c2838c8b5a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'After'\n",
    "resample_levels = [\"mouse\", \"session\", \"corrs_sm\"]\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        df_list = []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            df_list.append(pfs.pf_corrs_to_df(mouse, arena, day1, arena, day2))\n",
    "        \n",
    "        corr_df = pd.concat(df_list)\n",
    "        corr_df.insert(0, column='Group', value=group_name)\n",
    "        corr_df.insert(1, column=\"session_pair\", value=corr_df.apply(gen_sesh_id, axis=1))\n",
    "        corr_df_all.append(corr_df)\n",
    "        means = []\n",
    "        for ii in range(10000):\n",
    "            t = resample(corr_df, level=['mouse', 'session_pair', 'corrs_sm'])\n",
    "            means.append(t.corrs_sm.mean())\n",
    "        df_bs.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \"Mean PF Corr\": means}))\n",
    "df_bs = pd.concat(df_bs)\n",
    "corr_df_all = pd.concat(corr_df_all)\n",
    "corr_df_all = corr_df_all.rename(columns={\"arena1\" : \"Arena\"})\n",
    "corr_df_all.loc[corr_df_all.Arena == \"Open\", \"Arena\"] = \"Neutral\"\n",
    "\n",
    "save_df(corr_df_all, \"group_pf_corrs_after\")\n",
    "save_df(df_bs, \"group_pf_corrs_after_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221ac22b-3429-439a-a778-8e6b8de2f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'After2'\n",
    "resample_levels = [\"mouse\", \"session\", \"corrs_sm\"]\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        df_list = []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            df_list.append(pfs.pf_corrs_to_df(mouse, arena, day1, arena, day2))\n",
    "        \n",
    "        corr_df = pd.concat(df_list)\n",
    "        corr_df.insert(0, column='Group', value=group_name)\n",
    "        corr_df.insert(1, column=\"session_pair\", value=corr_df.apply(gen_sesh_id, axis=1))\n",
    "        corr_df_all.append(corr_df)\n",
    "        means = []\n",
    "        for ii in range(10000):\n",
    "            t = resample(corr_df, level=['mouse', 'session_pair', 'corrs_sm'])\n",
    "            means.append(t.corrs_sm.mean())\n",
    "        df_bs.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \"Mean PF Corr\": means}))\n",
    "df_bs = pd.concat(df_bs)\n",
    "corr_df_all = pd.concat(corr_df_all)\n",
    "corr_df_all = corr_df_all.rename(columns={\"arena1\" : \"Arena\"})\n",
    "corr_df_all.loc[corr_df_all.Arena == \"Open\", \"Arena\"] = \"Neutral\"\n",
    "\n",
    "save_df(corr_df_all, \"group_pf_corrs_after2\")\n",
    "save_df(df_bs, \"group_pf_corrs_after2_bootstrap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b179e5-94d9-4f9c-b836-0f07f83a824b",
   "metadata": {},
   "source": [
    "#### STM (4hr) comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c6de43-d10b-4218-8445-f039c369207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'Before v STM'\n",
    "resample_levels = [\"mouse\", \"session\", \"corrs_sm\"]\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        df_list = []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            df_list.append(pfs.pf_corrs_to_df(mouse, arena, day1, arena, day2))\n",
    "        \n",
    "        corr_df = pd.concat(df_list)\n",
    "        corr_df.insert(0, column='Group', value=group_name)\n",
    "        corr_df.insert(1, column=\"session_pair\", value=corr_df.apply(gen_sesh_id, axis=1))\n",
    "        corr_df_all.append(corr_df)\n",
    "        means = []\n",
    "        for ii in range(10000):\n",
    "            t = resample(corr_df, level=['mouse', 'session_pair', 'corrs_sm'])\n",
    "            means.append(t.corrs_sm.mean())\n",
    "        df_bs.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \"Mean PF Corr\": means}))\n",
    "df_bs = pd.concat(df_bs)\n",
    "corr_df_all = pd.concat(corr_df_all)\n",
    "corr_df_all = corr_df_all.rename(columns={\"arena1\" : \"Arena\"})\n",
    "corr_df_all.loc[corr_df_all.Arena == \"Open\", \"Arena\"] = \"Neutral\"\n",
    "\n",
    "save_df(corr_df_all, \"group_pf_corrs_before_stm\")\n",
    "save_df(df_bs, \"group_pf_corrs_before_stm_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342ec8a5-756c-4032-979d-39261b4ee9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'STM v After'\n",
    "resample_levels = [\"mouse\", \"session\", \"corrs_sm\"]\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        df_list = []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            df_list.append(pfs.pf_corrs_to_df(mouse, arena, day1, arena, day2))\n",
    "        \n",
    "        corr_df = pd.concat(df_list)\n",
    "        corr_df.insert(0, column='Group', value=group_name)\n",
    "        corr_df.insert(1, column=\"session_pair\", value=corr_df.apply(gen_sesh_id, axis=1))\n",
    "        corr_df_all.append(corr_df)\n",
    "        means = []\n",
    "        for ii in range(10000):\n",
    "            t = resample(corr_df, level=['mouse', 'session_pair', 'corrs_sm'])\n",
    "            means.append(t.corrs_sm.mean())\n",
    "        df_bs.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \"Mean PF Corr\": means}))\n",
    "df_bs = pd.concat(df_bs)\n",
    "corr_df_all = pd.concat(corr_df_all)\n",
    "corr_df_all = corr_df_all.rename(columns={\"arena1\" : \"Arena\"})\n",
    "corr_df_all.loc[corr_df_all.Arena == \"Open\", \"Arena\"] = \"Neutral\"\n",
    "\n",
    "save_df(corr_df_all, \"group_pf_corrs_stm_after\")\n",
    "save_df(df_bs, \"group_pf_corrs_stm_after_bootstrap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c136f4ae-4063-449f-80b5-0baa9a442110",
   "metadata": {},
   "source": [
    "### Quick and dirty sanity check plots\n",
    "Looks good - matches mean data at mouse level from original submission.\n",
    "real stuff in `Figure2_and_S4-5.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9dbf0b-1b05-4943-b29f-2723a6d28253",
   "metadata": {},
   "outputs": [],
   "source": [
    "for varname, epoch_name in zip([\"before\", \"before_after\", \"after\", \"after2\"],\n",
    "                               [\"Before\", \"Before v After\", \"After\", \"After2\"]):\n",
    "\n",
    "    corr_df = load_df(f\"group_pf_corrs_{varname}\")\n",
    "    boot_df = load_df(f\"group_pf_corrs_{varname}_bootstrap\")\n",
    "\n",
    "    corr_df.loc[corr_df.Arena == \"Open\", \"Arena\"] = \"Neutral\" \n",
    "    corr_df[\"Group\"] = pd.Categorical(corr_df[\"Group\"], [\"Learners\", \"Non-Learners\", \"ANI\"])\n",
    "    corr_df[\"Arena\"] = pd.Categorical(corr_df[\"Arena\"], [\"Neutral\", \"Shock\"])\n",
    "    \n",
    "    boot_df[\"Group\"] = pd.Categorical(boot_df[\"Group\"], [\"Learners\", \"Non-Learners\", \"ANI\"])\n",
    "    boot_df[\"Arena\"] = pd.Categorical(boot_df[\"Arena\"], [\"Neutral\", \"Shock\"])\n",
    "    \n",
    "    \n",
    "    # corr_means = corr_df.groupby([\"Group\", \"Arena\", \"mouse\"]).mean(numeric_only=True).reset_index()\n",
    "    # corr_means = corr_df.groupby([\"Group\", \"Arena\", \"mouse\"]).apply(np.nanmean).\n",
    "    corr_means = corr_df.drop(columns=[\"session_pair\", \"day1\", \"arena2\", \"day2\", \"pair_no\"]).groupby([\"Group\", \"Arena\", \"mouse\"]).apply(np.nanmean).reset_index()\n",
    "    corr_means = corr_means.rename(columns={0: \"corrs_sm\"})\n",
    "    corr_means[\"Group\"] = pd.Categorical(corr_means[\"Group\"], [\"Learners\", \"Non-Learners\", \"ANI\"])\n",
    "    corr_means[\"arena1\"] = pd.Categorical(corr_means[\"Arena\"], [\"Neutral\", \"Shock\"])\n",
    "    \n",
    "    _, ax = plt.subplots()\n",
    "    pal_use = sns.color_palette(palette='Set2', as_cmap=False)[0:3] \n",
    "    sns.boxplot(data=boot_df, x=\"Arena\", y=\"Mean PF Corr\", hue=\"Group\", showfliers=False, fill=False, palette=pal_use, ax=ax)\n",
    "    sns.stripplot(data=corr_means, x=\"Arena\", y=\"corrs_sm\", hue=\"Group\", dodge=True, palette=pal_use, linewidth=0.2, edgecolor='w',\n",
    "                  ax=ax, legend=False)\n",
    "    sns.despine(ax=ax)\n",
    "    ax.set_title(epoch_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e8eacf-028b-44e2-a4a1-429910e561e2",
   "metadata": {},
   "source": [
    "# PV1d correlation bootstraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769e60a-b0a2-4269-a91a-c46199fc2bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "resample_mice = rng.choice(mice, size=len(mice), replace=True)\n",
    "resample_mice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c168cf-f090-4f62-9014-6083b951f468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3338316671803213, -0.20040189480599838)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def resample_pv1d(mice, arena, day1, day2, shuf_map=False):\n",
    "    rng = np.random.default_rng()\n",
    "    resample_mice = rng.choice(mice, size=len(mice), replace=True)\n",
    "\n",
    "    pv_corrs_both, pv_corrs_all = [], []\n",
    "    for mouse in mice:\n",
    "        # day1, day2 = day_dict[epoch]\n",
    "        corr_all, corr_both = pfs.PV1_corr_bw_sesh(mouse, arena, day1, arena, day2, bootstrap=True, shuf_map=shuf_map)\n",
    "        pv_corrs_both.append(corr_both)\n",
    "        pv_corrs_all.append(corr_all)\n",
    "\n",
    "    return np.mean(pv_corrs_both), np.mean(pv_corrs_all)\n",
    "resample_pv1d(err.learners, 'Shock', 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb46ec9-c14e-4a8b-a448-aa1dce021efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_pf2d(mice, arena, day1, day2, shuf_map=False):\n",
    "    \"\"\"Generally used to resample 2d place map correlations\"\"\"\n",
    "    rng = np.random.default_rng()\n",
    "    resample_mice = rng.choice(mice, size=len(mice), replace=True)\n",
    "\n",
    "    pv_corrs_both, pv_corrs_all = [], []\n",
    "    for mouse in mice:\n",
    "        # day1, day2 = day_dict[epoch]\n",
    "        corr_all, corr_both = pfs.pf_corr_bw_sesh_corr_bw_sesh(mouse, arena, day1, arena, day2, shuf_map=shuf_map)\n",
    "        pv_corrs_both.append(corr_both)\n",
    "        pv_corrs_all.append(corr_all)\n",
    "\n",
    "    return np.mean(pv_corrs_both), np.mean(pv_corrs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236756c-6203-4131-9f6b-512d7a8b5b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to test parallelization\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import functools\n",
    "\n",
    "arena = 'Shock'\n",
    "day1, day2 = 1, 2\n",
    "\n",
    "partial_resample = functools.partial(resample_pv1d, arena=arena, day1=day1, day2=day2)\n",
    "n_iter = 10000\n",
    "n_jobs = 8\n",
    "out_df = []\n",
    "\n",
    "data = [\n",
    "    r\n",
    "    for r in tqdm(\n",
    "        Parallel(n_jobs=n_jobs, return_as=\"generator\")(\n",
    "            delayed(partial_resample)(err.learners) for _ in range(n_iter)\n",
    "        ),\n",
    "        total=n_iter,\n",
    "        # position=1,\n",
    "        # leave=False,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1647cfb9-fddf-4124-a1d1-bb02d5906bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import functools\n",
    "def bootstrap_resample_pv1d(mice, arena, day1, day2, group, comparison, arena_rename, shuf_map=False, n_iter=1000, n_jobs=12):\n",
    "    partial_resample = functools.partial(resample_pv1d, arena=arena, day1=day1, day2=day2, shuf_map=shuf_map)\n",
    "\n",
    "    data = [\n",
    "        r\n",
    "        for r in tqdm(\n",
    "            Parallel(n_jobs=n_jobs, return_as=\"generator\")(\n",
    "                delayed(partial_resample)(mice) for _ in range(n_iter)\n",
    "            ),\n",
    "            total=n_iter,\n",
    "            # position=1,\n",
    "            # leave=False,\n",
    "        )\n",
    "    ]\n",
    "    return pd.DataFrame({\"Group\": group, \"Arena\": arena_rename, \"Comparison\": comparison, \n",
    "                         \"Mean 1d PV Corr (Both)\": np.array(data)[:, 0], \"Mean 1d PV Corr (All)\": np.array(data)[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef11ccba-8d6e-46e1-9c8b-a29eede1fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        pv_means_both, pv_means_all = [], []\n",
    "        print(f'resampling for {arena_name} {group_name}')\n",
    "\n",
    "        day1, day2 = day_dict[\"Before\"]\n",
    "        data = bootstrap_resample_pv1d(mice, arena, day1, day2, group_name, epoch, arena_name, n_iter=n_iter)\n",
    "        boot_df.append(data)\n",
    "boot_df = pd.concat(boot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee056d77-1f9c-4981-9c79-428ed7cb99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "n_iter = 10000\n",
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'Before'\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        pv_means_both, pv_means_all = [], []\n",
    "        print(f'resampling for {arena_name} {group_name}')\n",
    "\n",
    "        day1, day2 = day_dict[epoch]\n",
    "        data = bootstrap_resample_pv1d(mice, arena, day1, day2, group_name, epoch, arena_name, n_iter=n_iter)\n",
    "        df_bs.append(data)\n",
    "df_bs = pd.concat(df_bs, ignore_index=True)\n",
    "\n",
    "# Do the same for session means without bootstrapping\n",
    "pvcorr_df = []\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                            [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "\n",
    "        pv_corrs_both, pv_corrs_all = [], []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            corr_all, corr_both = pfs.PV1_corr_bw_sesh(mouse, arena, day1, arena, day2, bootstrap=False)\n",
    "            pv_corrs_both.append(corr_both)\n",
    "            pv_corrs_all.append(corr_all)\n",
    "        pvcorr_df.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \n",
    "                                   \"1d PV Corr (Both)\": pv_corrs_both, \"1d PV Corr (All)\": pv_corrs_all}))\n",
    "\n",
    "pvcorr_df = pd.concat(pvcorr_df, ignore_index=True)\n",
    "\n",
    "save_df(pvcorr_df, \"group_pv1d_corrs_before\")\n",
    "save_df(df_bs, \"group_pv1d_corrs_before_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3963f5-06f0-4ca3-94b9-ff3f2a826f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'Before v After'\n",
    "resample_levels = [\"mouse\", \"session\", \"corrs_sm\"]\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        pv_means_both, pv_means_all = [], []\n",
    "        print(f'resampling for {arena_name} {group_name}')\n",
    "\n",
    "        day1, day2 = day_dict[epoch]\n",
    "        data = bootstrap_resample_pv1d(mice, arena, day1, day2, group_name, epoch, arena_name, n_iter=n_iter)\n",
    "        df_bs.append(data)\n",
    "df_bs = pd.concat(df_bs, ignore_index=True)\n",
    "\n",
    "# Do the same for session means without bootstrapping\n",
    "pvcorr_df = []\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                            [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "\n",
    "        pv_corrs_both, pv_corrs_all = [], []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            corr_all, corr_both = pfs.PV1_corr_bw_sesh(mouse, arena, day1, arena, day2, bootstrap=False)\n",
    "            pv_corrs_both.append(corr_both)\n",
    "            pv_corrs_all.append(corr_all)\n",
    "        pvcorr_df.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \n",
    "                                   \"1d PV Corr (Both)\": pv_corrs_both, \"1d PV Corr (All)\": pv_corrs_all}))\n",
    "\n",
    "pvcorr_df = pd.concat(pvcorr_df, ignore_index=True)\n",
    "\n",
    "save_df(pvcorr_df, \"group_pv1d_corrs_before_after\")\n",
    "save_df(df_bs, \"group_pv1d_corrs_before_after_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7db32-cbc5-4521-902d-979e236e2bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'After'\n",
    "resample_levels = [\"mouse\", \"session\", \"corrs_sm\"]\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        pv_means_both, pv_means_all = [], []\n",
    "        print(f'resampling for {arena_name} {group_name}')\n",
    "\n",
    "        day1, day2 = day_dict[epoch]\n",
    "        data = bootstrap_resample_pv1d(mice, arena, day1, day2, group_name, epoch, arena_name, n_iter=n_iter)\n",
    "        df_bs.append(data)\n",
    "df_bs = pd.concat(df_bs, ignore_index=True)\n",
    "\n",
    "# Do the same for session means without bootstrapping\n",
    "pvcorr_df = []\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                            [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "\n",
    "        pv_corrs_both, pv_corrs_all = [], []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            corr_all, corr_both = pfs.PV1_corr_bw_sesh(mouse, arena, day1, arena, day2, bootstrap=False)\n",
    "            pv_corrs_both.append(corr_both)\n",
    "            pv_corrs_all.append(corr_all)\n",
    "        pvcorr_df.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \n",
    "                                   \"1d PV Corr (Both)\": pv_corrs_both, \"1d PV Corr (All)\": pv_corrs_all}))\n",
    "\n",
    "pvcorr_df = pd.concat(pvcorr_df, ignore_index=True)\n",
    "\n",
    "save_df(pvcorr_df, \"group_pv1d_corrs_after\")\n",
    "save_df(df_bs, \"group_pv1d_corrs_after_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae92caa-60d0-4303-8861-dd62e445c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'Before v STM'\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        pv_means_both, pv_means_all = [], []\n",
    "        print(f'resampling for {arena_name} {group_name}')\n",
    "\n",
    "        day1, day2 = day_dict[epoch]\n",
    "        data = bootstrap_resample_pv1d(mice, arena, day1, day2, group_name, epoch, arena_name, n_iter=n_iter)\n",
    "        df_bs.append(data)\n",
    "df_bs = pd.concat(df_bs, ignore_index=True)\n",
    "\n",
    "# Do the same for session means without bootstrapping\n",
    "pvcorr_df = []\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                            [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "\n",
    "        pv_corrs_both, pv_corrs_all = [], []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            corr_all, corr_both = pfs.PV1_corr_bw_sesh(mouse, arena, day1, arena, day2, bootstrap=False)\n",
    "            pv_corrs_both.append(corr_both)\n",
    "            pv_corrs_all.append(corr_all)\n",
    "        pvcorr_df.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \n",
    "                                   \"1d PV Corr (Both)\": pv_corrs_both, \"1d PV Corr (All)\": pv_corrs_all}))\n",
    "\n",
    "pvcorr_df = pd.concat(pvcorr_df, ignore_index=True)\n",
    "\n",
    "save_df(pvcorr_df, \"group_pv1d_corrs_before_stm\")\n",
    "save_df(df_bs, \"group_pv1d_corrs_before_stm_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e143ed-9ccb-4c02-abc1-8d71308634c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'STM v After'\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        pv_means_both, pv_means_all = [], []\n",
    "        print(f'resampling for {arena_name} {group_name}')\n",
    "\n",
    "        day1, day2 = day_dict[epoch]\n",
    "        data = bootstrap_resample_pv1d(mice, arena, day1, day2, group_name, epoch, arena_name, n_iter=n_iter)\n",
    "        df_bs.append(data)\n",
    "df_bs = pd.concat(df_bs, ignore_index=True)\n",
    "\n",
    "# Do the same for session means without bootstrapping\n",
    "pvcorr_df = []\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                            [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "\n",
    "        pv_corrs_both, pv_corrs_all = [], []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            corr_all, corr_both = pfs.PV1_corr_bw_sesh(mouse, arena, day1, arena, day2, bootstrap=False)\n",
    "            pv_corrs_both.append(corr_both)\n",
    "            pv_corrs_all.append(corr_all)\n",
    "        pvcorr_df.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \n",
    "                                   \"1d PV Corr (Both)\": pv_corrs_both, \"1d PV Corr (All)\": pv_corrs_all}))\n",
    "\n",
    "pvcorr_df = pd.concat(pvcorr_df, ignore_index=True)\n",
    "\n",
    "save_df(pvcorr_df, \"group_pv1d_corrs_stm_after\")\n",
    "save_df(df_bs, \"group_pv1d_corrs_stm_after_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8e55911-31f7-46fb-b96a-abef1db7596e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Shock Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:58<00:00, 41.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:15<00:00, 39.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Shock Non-Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:38<00:00, 29.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:13<00:00, 31.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Shock ANI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [06:32<00:00, 25.51it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:17<00:00, 31.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [08:20<00:00, 19.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [08:56<00:00, 18.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral Non-Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [11:38<00:00, 14.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [10:18<00:00, 16.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral ANI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [09:35<00:00, 17.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [08:41<00:00, 19.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_pv1d_corrs_before.csv saved\n",
      "group_pv1d_corrs_before_bootstrap.csv saved\n",
      "resampling for Shock Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [02:33<00:00, 65.15it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [02:31<00:00, 65.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Shock Non-Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:31<00:00, 47.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:34<00:00, 46.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Shock ANI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:24<00:00, 37.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:59<00:00, 33.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:46<00:00, 28.88it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:40<00:00, 29.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral Non-Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [07:06<00:00, 23.43it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [06:52<00:00, 24.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral ANI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [07:36<00:00, 21.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [07:47<00:00, 21.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_pv1d_corrs_before_after.csv saved\n",
      "group_pv1d_corrs_before_after_bootstrap.csv saved\n",
      "resampling for Shock Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [02:15<00:00, 73.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [02:43<00:00, 61.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Shock Non-Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:13<00:00, 39.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:03<00:00, 32.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Shock ANI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:07<00:00, 32.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:39<00:00, 29.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [06:24<00:00, 25.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [06:10<00:00, 27.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral Non-Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [08:12<00:00, 20.31it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [07:37<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral ANI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [08:27<00:00, 19.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [09:09<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_pv1d_corrs_after.csv saved\n",
      "group_pv1d_corrs_after_bootstrap.csv saved\n",
      "resampling for Shock Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:41<00:00, 45.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:46<00:00, 44.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Shock Non-Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:46<00:00, 34.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:28<00:00, 37.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Shock ANI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:12<00:00, 31.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:23<00:00, 30.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [07:22<00:00, 22.61it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [07:01<00:00, 23.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral Non-Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [07:48<00:00, 21.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [08:54<00:00, 18.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral ANI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [09:17<00:00, 17.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [09:06<00:00, 18.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_pv1d_corrs_after2.csv saved\n",
      "group_pv1d_corrs_after2_bootstrap.csv saved\n",
      "resampling for Shock Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:04<00:00, 54.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:17<00:00, 50.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Shock Non-Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:26<00:00, 30.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:26<00:00, 30.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Shock ANI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [06:55<00:00, 24.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [06:17<00:00, 26.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:54<00:00, 28.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [06:11<00:00, 26.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral Non-Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [09:13<00:00, 18.08it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [08:53<00:00, 18.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral ANI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [09:22<00:00, 17.79it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [09:15<00:00, 18.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_pv1d_corrs_before_stm.csv saved\n",
      "group_pv1d_corrs_before_stm_bootstrap.csv saved\n",
      "resampling for Shock Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [02:36<00:00, 63.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [02:39<00:00, 62.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Shock Non-Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:04<00:00, 40.87it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:00<00:00, 41.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Shock ANI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:01<00:00, 41.45it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:04<00:00, 40.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:07<00:00, 32.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:18<00:00, 31.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral Non-Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [08:15<00:00, 20.17it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [09:33<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral ANI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [07:41<00:00, 21.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [07:20<00:00, 22.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_pv1d_corrs_stm_after.csv saved\n",
      "group_pv1d_corrs_stm_after_bootstrap.csv saved\n",
      "No placefields file found for Marble06 Shock day 7: creating PV1 from neural data only - NO SPEED THRESHOLDING\n",
      "No placefields file found for Marble06 Shock day 7: creating PV1 from neural data only - NO SPEED THRESHOLDING\n",
      "No placefields file found for Marble06 Shock day 7: creating PV1 from neural data only - NO SPEED THRESHOLDING\n",
      "No placefields file found for Marble06 Shock day 7: creating PV1 from neural data only - NO SPEED THRESHOLDING\n",
      "No placefields file found for Marble06 Shock day 7: creating PV1 from neural data only - NO SPEED THRESHOLDING\n",
      "No placefields file found for Marble06 Shock day 7: creating PV1 from neural data only - NO SPEED THRESHOLDING\n",
      "No placefields file found for Marble06 Shock day 7: creating PV1 from neural data only - NO SPEED THRESHOLDING\n",
      "No placefields file found for Marble06 Shock day 7: creating PV1 from neural data only - NO SPEED THRESHOLDING\n",
      "No placefields file found for Marble06 Shock day 7: creating PV1 from neural data only - NO SPEED THRESHOLDING\n",
      "No placefields file found for Marble06 Shock day 7: creating PV1 from neural data only - NO SPEED THRESHOLDING\n",
      "No placefields file found for Marble06 Shock day 7: creating PV1 from neural data only - NO SPEED THRESHOLDING\n",
      "No placefields file found for Marble06 Shock day 7: creating PV1 from neural data only - NO SPEED THRESHOLDING\n"
     ]
    }
   ],
   "source": [
    "n_iter = 10000\n",
    "for epoch in ['Before', 'Before v After', 'After', 'After2', 'Before v STM', 'STM v After']:\n",
    "    df_bs, df_shuf_bs, corr_df_all = [], [], []\n",
    "    for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "        \n",
    "        for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                    [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "            pv_means_both, pv_means_all = [], []\n",
    "            print(f'resampling for {arena_name} {group_name}')\n",
    "    \n",
    "            day1, day2 = day_dict[epoch]\n",
    "            data = bootstrap_resample_pv1d(mice, arena, day1, day2, group_name, epoch, arena_name, n_iter=n_iter)\n",
    "            shuf_data = bootstrap_resample_pv1d(mice, arena, day1, day2, group_name, epoch, arena_name, shuf_map=True, n_iter=n_iter)\n",
    "            df_bs.append(data)\n",
    "            df_shuf_bs.append(shuf_data)\n",
    "    df_bs = pd.concat(df_bs, ignore_index=True)\n",
    "    df_shuf_bs = pd.concat(df_shuf_bs, ignore_index=True)\n",
    "    \n",
    "    # Merge shuffled values into main DataFrame\n",
    "    df_bs = df_bs.merge(df_shuf_bs.rename(columns={\"Mean 1d PV Corr (Both)\" : \"Shuf 1d PV Corr (Both)\", \n",
    "                                                   \"Mean 1d PV Corr (All)\": \"Shuf 1d PV Corr (All)\"}), \n",
    "                        right_index=True, left_index=True, copy=False, \n",
    "                        suffixes=(None, \"2\")).drop(columns=[\"Group2\", \"Arena2\", \"Comparison2\"])\n",
    "    # Do the same for session means without bootstrapping\n",
    "    pvcorr_df = []\n",
    "    for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "        for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "    \n",
    "            pv_corrs_both, pv_corrs_all = [], []\n",
    "            for mouse in mice:\n",
    "                day1, day2 = day_dict[epoch]\n",
    "                corr_all, corr_both = pfs.PV1_corr_bw_sesh(mouse, arena, day1, arena, day2, bootstrap=False)\n",
    "                pv_corrs_both.append(corr_both)\n",
    "                pv_corrs_all.append(corr_all)\n",
    "            pvcorr_df.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \n",
    "                                           \"1d PV Corr (Both)\": pv_corrs_both, \"1d PV Corr (All)\": pv_corrs_all}))\n",
    "    \n",
    "    pvcorr_df = pd.concat(pvcorr_df, ignore_index=True)\n",
    "\n",
    "    save_str = savename_dict[epoch]\n",
    "    save_df(pvcorr_df, f\"group_pv1d_corrs_{save_str}\")\n",
    "    save_df(df_bs, f\"group_pv1d_corrs_{save_str}_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab580bf-4cfc-4be2-8689-b9025e325525",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvcorr_df = []\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                            [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "\n",
    "        pv_corrs_both, pv_corrs_all = [], []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            corr_both, corr_all = pfs.PV1_corr_bw_sesh(mouse, arena, day1, arena, day2, bootstrap=False)\n",
    "            pv_corrs_both.append(corr_both)\n",
    "            pv_corrs_all.append(corr_all)\n",
    "        pvcorr_df.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \n",
    "                                   \"1d PV Corr (Both)\": pv_corrs_both, \"1d PV Corr (All)\": pv_corrs_all}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af117a0-daa5-4f0a-9bd9-14bafd99dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(pvcorr_df, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
