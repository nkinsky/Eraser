{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63bc1a14-1ea6-4b08-8717-dc1d3b07cf57",
   "metadata": {},
   "source": [
    "Notebook to calculate and save place field correlation mean and hierarchically bootstrapped values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "501557f4-f1ec-41a2-a7b5-0e32a908dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sstats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import project specific modules and enable automatic reloading\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "eraser_path = Path(os.getcwd()).parent\n",
    "reinstatement_path = eraser_path.parent / 'FearReinstatement'\n",
    "sys.path.append(str(eraser_path))\n",
    "sys.path.append(str(reinstatement_path))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import eraser_reference as err\n",
    "import er_plot_functions as er\n",
    "from plotting import Fig, pretty_plot, FigMirror, fix_xlabels\n",
    "import placefield_stability as pfs\n",
    "import Placefields as pf\n",
    "import discrimination as discr\n",
    "import ca_traces as trc\n",
    "import cell_tracking as ct\n",
    "import er_plot_functions as erp\n",
    "from helpers import flatten\n",
    "from stats_utils import resample, get_bootstrap_prob, get_bootstrap_prob_paired\n",
    "from subjects import save_df, load_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a857741d-7ea1-40ec-9598-c7c8eec6d4b8",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d13347-0409-4fe6-b288-62b9b6971ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_dict = {\"Before\" : [-2, -1], \"Before v After\" : [-1, 1], \"After\" : [1, 2], \"After2\": [2, 7],\n",
    "            \"Before v STM\" : [-1, 4], \"STM v After\" : [4, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ee60769-f7b3-40a2-ad01-6facad1a145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sesh_id = lambda row : f\"{row['arena1']}{row['day1']}_{row['arena2']}{row['day2']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b797b63c-22ca-41a7-8922-908c7b090456",
   "metadata": {},
   "source": [
    "## 2D Place field correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d39431-aa0d-4817-9e6b-2fc9e817a4a6",
   "metadata": {},
   "source": [
    "### Before (Day -2 to -1) correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a8ee4-93a4-4d5f-b86e-ea75f7be552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'Before'\n",
    "resample_levels = [\"mouse\", \"session\", \"corrs_sm\"]\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        df_list = []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            df_list.append(pfs.pf_corrs_to_df(mouse, arena, day1, arena, day2))\n",
    "        \n",
    "        corr_df = pd.concat(df_list)\n",
    "        corr_df.insert(0, column='Group', value=group_name)\n",
    "        corr_df.insert(1, column=\"session_pair\", value=corr_df.apply(gen_sesh_id, axis=1))\n",
    "        corr_df_all.append(corr_df)\n",
    "        means = []\n",
    "        for ii in range(10000):\n",
    "            t = resample(corr_df, level=['mouse', 'session_pair', 'corrs_sm'])\n",
    "            means.append(t.corrs_sm.mean())\n",
    "        df_bs.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \"Mean PF Corr\": means}))\n",
    "df_bs = pd.concat(df_bs)\n",
    "corr_df_all = pd.concat(corr_df_all)\n",
    "corr_df_all = corr_df_all.rename(columns={\"arena1\" : \"Arena\"})\n",
    "corr_df_all.loc[corr_df_all.Arena == \"Open\", \"Arena\"] = \"Neutral\"\n",
    "\n",
    "save_df(corr_df_all, \"group_pf_corrs_before\")\n",
    "save_df(df_bs, \"group_pf_corrs_before_bootstrap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4080b37c-2dae-490c-a4f8-988da40d8fb8",
   "metadata": {},
   "source": [
    "### Calculate Before v After (Day -1 to Day 1) correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ff59c-81c0-4706-85ad-afec7239221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'Before v After'\n",
    "resample_levels = [\"mouse\", \"session\", \"corrs_sm\"]\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        df_list = []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            df_list.append(pfs.pf_corrs_to_df(mouse, arena, day1, arena, day2))\n",
    "        \n",
    "        corr_df = pd.concat(df_list)\n",
    "        corr_df.insert(0, column='Group', value=group_name)\n",
    "        corr_df.insert(1, column=\"session_pair\", value=corr_df.apply(gen_sesh_id, axis=1))\n",
    "        corr_df_all.append(corr_df)\n",
    "        means = []\n",
    "        for ii in range(10000):\n",
    "            t = resample(corr_df, level=['mouse', 'session_pair', 'corrs_sm'])\n",
    "            means.append(t.corrs_sm.mean())\n",
    "        df_bs.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \"Mean PF Corr\": means}))\n",
    "df_bs = pd.concat(df_bs)\n",
    "corr_df_all = pd.concat(corr_df_all)\n",
    "corr_df_all = corr_df_all.rename(columns={\"arena1\" : \"Arena\"})\n",
    "corr_df_all.loc[corr_df_all.Arena == \"Open\", \"Arena\"] = \"Neutral\"\n",
    "\n",
    "save_df(corr_df_all, \"group_pf_corrs_before_after\")\n",
    "save_df(df_bs, \"group_pf_corrs_before_after_bootstrap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd485a62-8f13-4660-a0b7-09a09646bdfe",
   "metadata": {},
   "source": [
    "### After correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf7c9c-2742-4f5d-82ae-c2838c8b5a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'After'\n",
    "resample_levels = [\"mouse\", \"session\", \"corrs_sm\"]\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        df_list = []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            df_list.append(pfs.pf_corrs_to_df(mouse, arena, day1, arena, day2))\n",
    "        \n",
    "        corr_df = pd.concat(df_list)\n",
    "        corr_df.insert(0, column='Group', value=group_name)\n",
    "        corr_df.insert(1, column=\"session_pair\", value=corr_df.apply(gen_sesh_id, axis=1))\n",
    "        corr_df_all.append(corr_df)\n",
    "        means = []\n",
    "        for ii in range(10000):\n",
    "            t = resample(corr_df, level=['mouse', 'session_pair', 'corrs_sm'])\n",
    "            means.append(t.corrs_sm.mean())\n",
    "        df_bs.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \"Mean PF Corr\": means}))\n",
    "df_bs = pd.concat(df_bs)\n",
    "corr_df_all = pd.concat(corr_df_all)\n",
    "corr_df_all = corr_df_all.rename(columns={\"arena1\" : \"Arena\"})\n",
    "corr_df_all.loc[corr_df_all.Arena == \"Open\", \"Arena\"] = \"Neutral\"\n",
    "\n",
    "save_df(corr_df_all, \"group_pf_corrs_after\")\n",
    "save_df(df_bs, \"group_pf_corrs_after_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221ac22b-3429-439a-a778-8e6b8de2f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'After2'\n",
    "resample_levels = [\"mouse\", \"session\", \"corrs_sm\"]\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        df_list = []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            df_list.append(pfs.pf_corrs_to_df(mouse, arena, day1, arena, day2))\n",
    "        \n",
    "        corr_df = pd.concat(df_list)\n",
    "        corr_df.insert(0, column='Group', value=group_name)\n",
    "        corr_df.insert(1, column=\"session_pair\", value=corr_df.apply(gen_sesh_id, axis=1))\n",
    "        corr_df_all.append(corr_df)\n",
    "        means = []\n",
    "        for ii in range(10000):\n",
    "            t = resample(corr_df, level=['mouse', 'session_pair', 'corrs_sm'])\n",
    "            means.append(t.corrs_sm.mean())\n",
    "        df_bs.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \"Mean PF Corr\": means}))\n",
    "df_bs = pd.concat(df_bs)\n",
    "corr_df_all = pd.concat(corr_df_all)\n",
    "corr_df_all = corr_df_all.rename(columns={\"arena1\" : \"Arena\"})\n",
    "corr_df_all.loc[corr_df_all.Arena == \"Open\", \"Arena\"] = \"Neutral\"\n",
    "\n",
    "save_df(corr_df_all, \"group_pf_corrs_after2\")\n",
    "save_df(df_bs, \"group_pf_corrs_after2_bootstrap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b179e5-94d9-4f9c-b836-0f07f83a824b",
   "metadata": {},
   "source": [
    "#### STM (4hr) comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c6de43-d10b-4218-8445-f039c369207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'Before v STM'\n",
    "resample_levels = [\"mouse\", \"session\", \"corrs_sm\"]\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        df_list = []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            df_list.append(pfs.pf_corrs_to_df(mouse, arena, day1, arena, day2))\n",
    "        \n",
    "        corr_df = pd.concat(df_list)\n",
    "        corr_df.insert(0, column='Group', value=group_name)\n",
    "        corr_df.insert(1, column=\"session_pair\", value=corr_df.apply(gen_sesh_id, axis=1))\n",
    "        corr_df_all.append(corr_df)\n",
    "        means = []\n",
    "        for ii in range(10000):\n",
    "            t = resample(corr_df, level=['mouse', 'session_pair', 'corrs_sm'])\n",
    "            means.append(t.corrs_sm.mean())\n",
    "        df_bs.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \"Mean PF Corr\": means}))\n",
    "df_bs = pd.concat(df_bs)\n",
    "corr_df_all = pd.concat(corr_df_all)\n",
    "corr_df_all = corr_df_all.rename(columns={\"arena1\" : \"Arena\"})\n",
    "corr_df_all.loc[corr_df_all.Arena == \"Open\", \"Arena\"] = \"Neutral\"\n",
    "\n",
    "save_df(corr_df_all, \"group_pf_corrs_before_stm\")\n",
    "save_df(df_bs, \"group_pf_corrs_before_stm_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342ec8a5-756c-4032-979d-39261b4ee9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'STM v After'\n",
    "resample_levels = [\"mouse\", \"session\", \"corrs_sm\"]\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        df_list = []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            df_list.append(pfs.pf_corrs_to_df(mouse, arena, day1, arena, day2))\n",
    "        \n",
    "        corr_df = pd.concat(df_list)\n",
    "        corr_df.insert(0, column='Group', value=group_name)\n",
    "        corr_df.insert(1, column=\"session_pair\", value=corr_df.apply(gen_sesh_id, axis=1))\n",
    "        corr_df_all.append(corr_df)\n",
    "        means = []\n",
    "        for ii in range(10000):\n",
    "            t = resample(corr_df, level=['mouse', 'session_pair', 'corrs_sm'])\n",
    "            means.append(t.corrs_sm.mean())\n",
    "        df_bs.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \"Mean PF Corr\": means}))\n",
    "df_bs = pd.concat(df_bs)\n",
    "corr_df_all = pd.concat(corr_df_all)\n",
    "corr_df_all = corr_df_all.rename(columns={\"arena1\" : \"Arena\"})\n",
    "corr_df_all.loc[corr_df_all.Arena == \"Open\", \"Arena\"] = \"Neutral\"\n",
    "\n",
    "save_df(corr_df_all, \"group_pf_corrs_stm_after\")\n",
    "save_df(df_bs, \"group_pf_corrs_stm_after_bootstrap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c136f4ae-4063-449f-80b5-0baa9a442110",
   "metadata": {},
   "source": [
    "### Quick and dirty sanity check plots\n",
    "Looks good - matches mean data at mouse level from original submission.\n",
    "real stuff in `Figure2_and_S4-5.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9dbf0b-1b05-4943-b29f-2723a6d28253",
   "metadata": {},
   "outputs": [],
   "source": [
    "for varname, epoch_name in zip([\"before\", \"before_after\", \"after\", \"after2\"],\n",
    "                               [\"Before\", \"Before v After\", \"After\", \"After2\"]):\n",
    "\n",
    "    corr_df = load_df(f\"group_pf_corrs_{varname}\")\n",
    "    boot_df = load_df(f\"group_pf_corrs_{varname}_bootstrap\")\n",
    "\n",
    "    corr_df.loc[corr_df.Arena == \"Open\", \"Arena\"] = \"Neutral\" \n",
    "    corr_df[\"Group\"] = pd.Categorical(corr_df[\"Group\"], [\"Learners\", \"Non-Learners\", \"ANI\"])\n",
    "    corr_df[\"Arena\"] = pd.Categorical(corr_df[\"Arena\"], [\"Neutral\", \"Shock\"])\n",
    "    \n",
    "    boot_df[\"Group\"] = pd.Categorical(boot_df[\"Group\"], [\"Learners\", \"Non-Learners\", \"ANI\"])\n",
    "    boot_df[\"Arena\"] = pd.Categorical(boot_df[\"Arena\"], [\"Neutral\", \"Shock\"])\n",
    "    \n",
    "    \n",
    "    # corr_means = corr_df.groupby([\"Group\", \"Arena\", \"mouse\"]).mean(numeric_only=True).reset_index()\n",
    "    # corr_means = corr_df.groupby([\"Group\", \"Arena\", \"mouse\"]).apply(np.nanmean).\n",
    "    corr_means = corr_df.drop(columns=[\"session_pair\", \"day1\", \"arena2\", \"day2\", \"pair_no\"]).groupby([\"Group\", \"Arena\", \"mouse\"]).apply(np.nanmean).reset_index()\n",
    "    corr_means = corr_means.rename(columns={0: \"corrs_sm\"})\n",
    "    corr_means[\"Group\"] = pd.Categorical(corr_means[\"Group\"], [\"Learners\", \"Non-Learners\", \"ANI\"])\n",
    "    corr_means[\"arena1\"] = pd.Categorical(corr_means[\"Arena\"], [\"Neutral\", \"Shock\"])\n",
    "    \n",
    "    _, ax = plt.subplots()\n",
    "    pal_use = sns.color_palette(palette='Set2', as_cmap=False)[0:3] \n",
    "    sns.boxplot(data=boot_df, x=\"Arena\", y=\"Mean PF Corr\", hue=\"Group\", showfliers=False, fill=False, palette=pal_use, ax=ax)\n",
    "    sns.stripplot(data=corr_means, x=\"Arena\", y=\"corrs_sm\", hue=\"Group\", dodge=True, palette=pal_use, linewidth=0.2, edgecolor='w',\n",
    "                  ax=ax, legend=False)\n",
    "    sns.despine(ax=ax)\n",
    "    ax.set_title(epoch_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e8eacf-028b-44e2-a4a1-429910e561e2",
   "metadata": {},
   "source": [
    "# PV1d correlation bootstraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769e60a-b0a2-4269-a91a-c46199fc2bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "resample_mice = rng.choice(mice, size=len(mice), replace=True)\n",
    "resample_mice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c168cf-f090-4f62-9014-6083b951f468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3338316671803213, -0.20040189480599838)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def resample_pv1d(mice, arena, day1, day2, shuf_map=False):\n",
    "    rng = np.random.default_rng()\n",
    "    resample_mice = rng.choice(mice, size=len(mice), replace=True)\n",
    "\n",
    "    pv_corrs_both, pv_corrs_all = [], []\n",
    "    for mouse in mice:\n",
    "        # day1, day2 = day_dict[epoch]\n",
    "        corr_all, corr_both = pfs.PV1_corr_bw_sesh(mouse, arena, day1, arena, day2, bootstrap=True, shuf_map=shuf_map)\n",
    "        pv_corrs_both.append(corr_both)\n",
    "        pv_corrs_all.append(corr_all)\n",
    "\n",
    "    return np.mean(pv_corrs_both), np.mean(pv_corrs_all)\n",
    "resample_pv1d(err.learners, 'Shock', 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236756c-6203-4131-9f6b-512d7a8b5b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to test parallelization\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import functools\n",
    "\n",
    "arena = 'Shock'\n",
    "day1, day2 = 1, 2\n",
    "\n",
    "partial_resample = functools.partial(resample_pv1d, arena=arena, day1=day1, day2=day2)\n",
    "n_iter = 10000\n",
    "n_jobs = 8\n",
    "out_df = []\n",
    "\n",
    "data = [\n",
    "    r\n",
    "    for r in tqdm(\n",
    "        Parallel(n_jobs=n_jobs, return_as=\"generator\")(\n",
    "            delayed(partial_resample)(err.learners) for _ in range(n_iter)\n",
    "        ),\n",
    "        total=n_iter,\n",
    "        # position=1,\n",
    "        # leave=False,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1647cfb9-fddf-4124-a1d1-bb02d5906bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import functools\n",
    "def bootstrap_resample_pv1d(mice, arena, day1, day2, group, comparison, arena_rename, shuf_map=False, n_iter=1000, n_jobs=12):\n",
    "    partial_resample = functools.partial(resample_pv1d, arena=arena, day1=day1, day2=day2, shuf_map=shuf_map)\n",
    "\n",
    "    data = [\n",
    "        r\n",
    "        for r in tqdm(\n",
    "            Parallel(n_jobs=n_jobs, return_as=\"generator\")(\n",
    "                delayed(partial_resample)(mice) for _ in range(n_iter)\n",
    "            ),\n",
    "            total=n_iter,\n",
    "            # position=1,\n",
    "            # leave=False,\n",
    "        )\n",
    "    ]\n",
    "    return pd.DataFrame({\"Group\": group, \"Arena\": arena_rename, \"Comparison\": comparison, \n",
    "                         \"Mean 1d PV Corr (Both)\": np.array(data)[:, 0], \t\"Mean 1d PV Corr (All)\": np.array(data)[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef11ccba-8d6e-46e1-9c8b-a29eede1fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        pv_means_both, pv_means_all = [], []\n",
    "        print(f'resampling for {arena_name} {group_name}')\n",
    "\n",
    "        day1, day2 = day_dict[\"Before\"]\n",
    "        data = bootstrap_resample_pv1d(mice, arena, day1, day2, group_name, epoch, arena_name, n_iter=n_iter)\n",
    "        boot_df.append(data)\n",
    "boot_df = pd.concat(boot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee056d77-1f9c-4981-9c79-428ed7cb99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "n_iter = 10000\n",
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'Before'\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        pv_means_both, pv_means_all = [], []\n",
    "        print(f'resampling for {arena_name} {group_name}')\n",
    "\n",
    "        day1, day2 = day_dict[epoch]\n",
    "        data = bootstrap_resample_pv1d(mice, arena, day1, day2, group_name, epoch, arena_name, n_iter=n_iter)\n",
    "        df_bs.append(data)\n",
    "df_bs = pd.concat(df_bs, ignore_index=True)\n",
    "\n",
    "# Do the same for session means without bootstrapping\n",
    "pvcorr_df = []\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                            [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "\n",
    "        pv_corrs_both, pv_corrs_all = [], []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            corr_all, corr_both = pfs.PV1_corr_bw_sesh(mouse, arena, day1, arena, day2, bootstrap=False)\n",
    "            pv_corrs_both.append(corr_both)\n",
    "            pv_corrs_all.append(corr_all)\n",
    "        pvcorr_df.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \n",
    "                                   \"1d PV Corr (Both)\": pv_corrs_both, \"1d PV Corr (All)\": pv_corrs_all}))\n",
    "\n",
    "pvcorr_df = pd.concat(pvcorr_df, ignore_index=True)\n",
    "\n",
    "save_df(pvcorr_df, \"group_pv1d_corrs_before\")\n",
    "save_df(df_bs, \"group_pv1d_corrs_before_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3963f5-06f0-4ca3-94b9-ff3f2a826f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'Before v After'\n",
    "resample_levels = [\"mouse\", \"session\", \"corrs_sm\"]\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        pv_means_both, pv_means_all = [], []\n",
    "        print(f'resampling for {arena_name} {group_name}')\n",
    "\n",
    "        day1, day2 = day_dict[epoch]\n",
    "        data = bootstrap_resample_pv1d(mice, arena, day1, day2, group_name, epoch, arena_name, n_iter=n_iter)\n",
    "        df_bs.append(data)\n",
    "df_bs = pd.concat(df_bs, ignore_index=True)\n",
    "\n",
    "# Do the same for session means without bootstrapping\n",
    "pvcorr_df = []\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                            [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "\n",
    "        pv_corrs_both, pv_corrs_all = [], []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            corr_all, corr_both = pfs.PV1_corr_bw_sesh(mouse, arena, day1, arena, day2, bootstrap=False)\n",
    "            pv_corrs_both.append(corr_both)\n",
    "            pv_corrs_all.append(corr_all)\n",
    "        pvcorr_df.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \n",
    "                                   \"1d PV Corr (Both)\": pv_corrs_both, \"1d PV Corr (All)\": pv_corrs_all}))\n",
    "\n",
    "pvcorr_df = pd.concat(pvcorr_df, ignore_index=True)\n",
    "\n",
    "save_df(pvcorr_df, \"group_pv1d_corrs_before_after\")\n",
    "save_df(df_bs, \"group_pv1d_corrs_before_after_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7db32-cbc5-4521-902d-979e236e2bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'After'\n",
    "resample_levels = [\"mouse\", \"session\", \"corrs_sm\"]\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        pv_means_both, pv_means_all = [], []\n",
    "        print(f'resampling for {arena_name} {group_name}')\n",
    "\n",
    "        day1, day2 = day_dict[epoch]\n",
    "        data = bootstrap_resample_pv1d(mice, arena, day1, day2, group_name, epoch, arena_name, n_iter=n_iter)\n",
    "        df_bs.append(data)\n",
    "df_bs = pd.concat(df_bs, ignore_index=True)\n",
    "\n",
    "# Do the same for session means without bootstrapping\n",
    "pvcorr_df = []\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                            [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "\n",
    "        pv_corrs_both, pv_corrs_all = [], []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            corr_all, corr_both = pfs.PV1_corr_bw_sesh(mouse, arena, day1, arena, day2, bootstrap=False)\n",
    "            pv_corrs_both.append(corr_both)\n",
    "            pv_corrs_all.append(corr_all)\n",
    "        pvcorr_df.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \n",
    "                                   \"1d PV Corr (Both)\": pv_corrs_both, \"1d PV Corr (All)\": pv_corrs_all}))\n",
    "\n",
    "pvcorr_df = pd.concat(pvcorr_df, ignore_index=True)\n",
    "\n",
    "save_df(pvcorr_df, \"group_pv1d_corrs_after\")\n",
    "save_df(df_bs, \"group_pv1d_corrs_after_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae92caa-60d0-4303-8861-dd62e445c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'Before v STM'\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        pv_means_both, pv_means_all = [], []\n",
    "        print(f'resampling for {arena_name} {group_name}')\n",
    "\n",
    "        day1, day2 = day_dict[epoch]\n",
    "        data = bootstrap_resample_pv1d(mice, arena, day1, day2, group_name, epoch, arena_name, n_iter=n_iter)\n",
    "        df_bs.append(data)\n",
    "df_bs = pd.concat(df_bs, ignore_index=True)\n",
    "\n",
    "# Do the same for session means without bootstrapping\n",
    "pvcorr_df = []\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                            [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "\n",
    "        pv_corrs_both, pv_corrs_all = [], []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            corr_all, corr_both = pfs.PV1_corr_bw_sesh(mouse, arena, day1, arena, day2, bootstrap=False)\n",
    "            pv_corrs_both.append(corr_both)\n",
    "            pv_corrs_all.append(corr_all)\n",
    "        pvcorr_df.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \n",
    "                                   \"1d PV Corr (Both)\": pv_corrs_both, \"1d PV Corr (All)\": pv_corrs_all}))\n",
    "\n",
    "pvcorr_df = pd.concat(pvcorr_df, ignore_index=True)\n",
    "\n",
    "save_df(pvcorr_df, \"group_pv1d_corrs_before_stm\")\n",
    "save_df(df_bs, \"group_pv1d_corrs_before_stm_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e143ed-9ccb-4c02-abc1-8d71308634c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_bs, corr_df_all = [], []\n",
    "epoch = 'STM v After'\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        pv_means_both, pv_means_all = [], []\n",
    "        print(f'resampling for {arena_name} {group_name}')\n",
    "\n",
    "        day1, day2 = day_dict[epoch]\n",
    "        data = bootstrap_resample_pv1d(mice, arena, day1, day2, group_name, epoch, arena_name, n_iter=n_iter)\n",
    "        df_bs.append(data)\n",
    "df_bs = pd.concat(df_bs, ignore_index=True)\n",
    "\n",
    "# Do the same for session means without bootstrapping\n",
    "pvcorr_df = []\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                            [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "\n",
    "        pv_corrs_both, pv_corrs_all = [], []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            corr_all, corr_both = pfs.PV1_corr_bw_sesh(mouse, arena, day1, arena, day2, bootstrap=False)\n",
    "            pv_corrs_both.append(corr_both)\n",
    "            pv_corrs_all.append(corr_all)\n",
    "        pvcorr_df.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \n",
    "                                   \"1d PV Corr (Both)\": pv_corrs_both, \"1d PV Corr (All)\": pv_corrs_all}))\n",
    "\n",
    "pvcorr_df = pd.concat(pvcorr_df, ignore_index=True)\n",
    "\n",
    "save_df(pvcorr_df, \"group_pv1d_corrs_stm_after\")\n",
    "save_df(df_bs, \"group_pv1d_corrs_stm_after_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "478002a0-d023-4356-8195-d4fa5373cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8e55911-31f7-46fb-b96a-abef1db7596e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Shock Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:21<00:00, 45.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 55.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Shock Non-Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:22<00:00, 43.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:30<00:00, 32.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Shock ANI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:29<00:00, 33.75it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:26<00:00, 38.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:34<00:00, 29.08it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:34<00:00, 28.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral Non-Learners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:43<00:00, 22.86it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:43<00:00, 23.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampling for Neutral ANI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:45<00:00, 22.12it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:46<00:00, 21.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_pv1d_corrs_after2.csv saved\n",
      "group_pv1d_corrs_after2_bootstrap.csv saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_bs, df_shuf_bs, corr_df_all = [], [], []\n",
    "epoch = 'After2'\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    \n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                                [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "        pv_means_both, pv_means_all = [], []\n",
    "        print(f'resampling for {arena_name} {group_name}')\n",
    "\n",
    "        day1, day2 = day_dict[epoch]\n",
    "        data = bootstrap_resample_pv1d(mice, arena, day1, day2, group_name, epoch, arena_name, n_iter=n_iter)\n",
    "        shuf_data = bootstrap_resample_pv1d(mice, arena, day1, day2, group_name, epoch, arena_name, shuf_map=True, n_iter=n_iter)\n",
    "        df_bs.append(data)\n",
    "        df_shuf_bs.append(shuf_data)\n",
    "df_bs = pd.concat(df_bs, ignore_index=True)\n",
    "df_shuf_bs = pd.concat(df_shuf_bs, ignore_index=True)\n",
    "\n",
    "# Merge shuffled values into main DataFrame\n",
    "df_bs = df_bs.merge(df_shuf_bs.rename(columns={\"Mean 1d PV Corr (Both)\" : \"Shuf 1d PV Corr (Both)\", \n",
    "                                       \"Mean 1d PV Corr (All)\": \"Shuf 1d PV Corr (All)\"}),\n",
    "            right_index=True, left_index=True, copy=False, suffixes=(None, \"2\")).drop(columns=[\"Group2\", \"Arena2\", \"Comparison2\"])\n",
    "# Do the same for session means without bootstrapping\n",
    "pvcorr_df = []\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                            [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "\n",
    "        pv_corrs_both, pv_corrs_all = [], []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            corr_all, corr_both = pfs.PV1_corr_bw_sesh(mouse, arena, day1, arena, day2, bootstrap=False)\n",
    "            pv_corrs_both.append(corr_both)\n",
    "            pv_corrs_all.append(corr_all)\n",
    "        pvcorr_df.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \n",
    "                                   \"1d PV Corr (Both)\": pv_corrs_both, \"1d PV Corr (All)\": pv_corrs_all}))\n",
    "\n",
    "pvcorr_df = pd.concat(pvcorr_df, ignore_index=True)\n",
    "\n",
    "save_df(pvcorr_df, \"group_pv1d_corrs_after2\")\n",
    "save_df(df_bs, \"group_pv1d_corrs_after2_bootstrap\")\n",
    "# save_df(df_shuf_bs, \"group_pv1d_shuf_corrs_after2_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab580bf-4cfc-4be2-8689-b9025e325525",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvcorr_df = []\n",
    "for arena, arena_name in zip(['Shock', 'Open'], ['Shock', 'Neutral']):\n",
    "    for group_name, mice in zip([\"Learners\", \"Non-Learners\", \"ANI\"], \n",
    "                            [err.learners, err.nonlearners, err.ani_mice_good]):\n",
    "\n",
    "        pv_corrs_both, pv_corrs_all = [], []\n",
    "        for mouse in mice:\n",
    "            day1, day2 = day_dict[epoch]\n",
    "            corr_both, corr_all = pfs.PV1_corr_bw_sesh(mouse, arena, day1, arena, day2, bootstrap=False)\n",
    "            pv_corrs_both.append(corr_both)\n",
    "            pv_corrs_all.append(corr_all)\n",
    "        pvcorr_df.append(pd.DataFrame({\"Group\": group_name, \"Arena\": arena_name, \"Comparison\": epoch, \n",
    "                                   \"1d PV Corr (Both)\": pv_corrs_both, \"1d PV Corr (All)\": pv_corrs_all}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af117a0-daa5-4f0a-9bd9-14bafd99dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(pvcorr_df, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
